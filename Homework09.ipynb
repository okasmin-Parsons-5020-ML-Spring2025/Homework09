{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QshK8s21WBrf"
   },
   "source": [
    "# Homework09\n",
    "\n",
    "Exercises to practice dimensionality reduction with PCA\n",
    "\n",
    "## Goals\n",
    "\n",
    "- Add unsupervised pre-processing to our ML flow: encode -> normalize -> pre-process -> train -> evaluate\n",
    "- Build an intuition for PCA and when/how to use it\n",
    "- Understand the benefits of dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Hf8SXUwWOho"
   },
   "source": [
    "### Setup\n",
    "\n",
    "Run the following 2 cells to import all necessary libraries and helpers for this homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/PSAM-5020-2025S-A/5020-utils/raw/main/src/data_utils.py\n",
    "!wget -q https://github.com/PSAM-5020-2025S-A/5020-utils/raw/main/src/image_utils.py\n",
    "!wget -q https://github.com/PSAM-5020-2025S-A/Homework07/raw/main/Homework07_utils.pyc\n",
    "\n",
    "!wget -qO- https://github.com/PSAM-5020-2025S-A/5020-utils/releases/latest/download/0801-500.tar.gz | tar xz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as PImage\n",
    "\n",
    "from os import listdir, path\n",
    "\n",
    "from data_utils import PCA, RandomForestClassifier\n",
    "\n",
    "from image_utils import get_pixels, make_image\n",
    "\n",
    "from Homework07_utils import CamUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA and Classification\n",
    "\n",
    "Let's practice doing some more image classification with `PCA` and analyzing the results.\n",
    "\n",
    "The dataset is the same one we used in `Homework07`. It has images from $25$ different security cameras, and our task is to separate them by camera. Some of the cameras move, some of them don't, and there are more than $1000$ images, so there's no way we want to do this by hand.\n",
    "\n",
    "Let's start by loading the training images into a list of pixels, like we did with the `faces` dataset in class.\n",
    "\n",
    "### Loading Data\n",
    "\n",
    "If we look at the images in `./data/image/0801-500/train/`, we'll notice that they are named and organized in a slightly different way. They're all in the same directory and the first part of their filename specifies which camera they came from. Even though those `ids` are numbers, they're not sequential, so we'll use some helper functions to extract a unique `label` from their filenames.\n",
    "\n",
    "This is exactly what the `OrdinalEncoder` class does, but since we only have to encode this one column, we'll do it by hand while we read the files in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this creates a list of all the files in a given directory, that end in .jpg\n",
    "train_files = [f for f in listdir(\"./data/image/0801-500/train\") if f.endswith(\".jpg\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: check and see what is inside the list here\n",
    "print(len(train_files))\n",
    "print(train_files[0])\n",
    "print(train_files[100])\n",
    "print(train_files[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll read the image pixels and extract their labels. `CamUtils.get_label()` is the helper function we'll use to \"encode\" and return a label id based on the filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_data = []\n",
    "label_data = []\n",
    "\n",
    "for fname in train_files:\n",
    "  label = CamUtils.get_label(fname)\n",
    "  img = PImage.open(path.join(\"./data/image/0801-500/train\", fname))\n",
    "  pixel_data.append(get_pixels(img))\n",
    "  label_data.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: check if labels got extracted correctly by looking at \n",
    "#       the first few items of the label list and the filename list\n",
    "\n",
    "print(label_data[0])\n",
    "print(train_files[0])\n",
    "\n",
    "print(label_data[1])\n",
    "print(train_files[1])\n",
    "\n",
    "print(label_data[10])\n",
    "print(train_files[10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like in `Homework07`, the labels and the filenames won't match exactly since labels start at $0$ and the filenames start at $01$ and skip some numbers.\n",
    "\n",
    "We can open some images from pixels, just to make sure we loaded them correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(make_image(pixel_data[0], width=256))\n",
    "display(make_image(pixel_data[10], width=256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n",
    "\n",
    "Create a `DataFrame` called `cam_pca_df` by running `PCA` on the list of pixel data, just like we did in class, and then append a `label` column to it, just like we did in Homewokr07 with: `train_df[\"label\"] = label_data`.\n",
    "\n",
    "You can change how many components to extract from the images later, but for this first run just use $10$ components so we can compare classification with $10$ `PCA` components to the classification with $10$ random features from `Homework07`.  Make sure to confirm how much of the `variance` is preserved by this transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: run PCA, get DataFrame\n",
    "pixel_pca = PCA(n_components=10)\n",
    "cam_pca_df = pixel_pca.fit_transform(pixel_data)\n",
    "\n",
    "# TODO: add \"label\" column\n",
    "cam_pca_df[\"label\"] = label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: print variance\n",
    "print(pixel_pca.explained_variance())\n",
    "\n",
    "# TODO: take a look at the first 5 rows\n",
    "cam_pca_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink\">\n",
    "How many components did you keep ?<br>\n",
    "Did you try different numbers ?<br>\n",
    "What percent of variance is kept by this transformation?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "10 PCA components results in ~0.78 variance.\n",
    "\n",
    "5 PCA components --> ~0.65 variance\n",
    "\n",
    "1 PCA component --> ~0.24 variance\n",
    "\n",
    "1 versus 10 PCA components is a very large difference, but 5 to 10 is less of a difference so depending on computation speed and ideal minimum variance it could be worth finding a sweet spot somewhere between 5 and 10. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruct\n",
    "\n",
    "Before we go run our classification, let's take a look at some reconstructed images, just to make sure they make sense.\n",
    "\n",
    "Take a look at reconstructed versions of images $0$, $10$, and whichever other images you might have opened above.\n",
    "\n",
    "We did this in class. It involves a `inverse_transform()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "pca_pixels = pixel_pca.inverse_transform(cam_pca_df)\n",
    "\n",
    "# TODO: reconstruct image at index 0\n",
    "display(make_image(pixel_data[0], width=256))\n",
    "display(make_image(pca_pixels.loc[0], width=256))\n",
    "\n",
    "# TODO: reconstruct image at index 10\n",
    "display(make_image(pixel_data[10], width=256))\n",
    "display(make_image(pca_pixels.loc[10], width=256))\n",
    "\n",
    "\n",
    "# the reconstruction of image 0 looks surprisingly bad... but image 10 looks okay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reconstructed images should look blurrier and noisier than the original ones, but they should still look something like the original ones.\n",
    "\n",
    "### Classify !\n",
    "\n",
    "Train a `RandomForestClassifier` on the `PCA` data.\n",
    "\n",
    "Remember to separate the output feature (`label`) from the input features (`PC0`, `PC1`, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: create a classifier\n",
    "model_rf = RandomForestClassifier()\n",
    "\n",
    "# TODO: split input and output features\n",
    "chosen_columns = cam_pca_df.columns[:10]\n",
    "train_features = cam_pca_df[chosen_columns]\n",
    "\n",
    "out_features = cam_pca_df[\"label\"]\n",
    "\n",
    "# TODO: fit the model\n",
    "model_rf.fit(train_features, out_features)\n",
    "\n",
    "# TODO: run predictions\n",
    "train_predictions = model_rf.predict(train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure Error\n",
    "\n",
    "For the train set we could use the generic `classification_error()` function that we've used before because we have the true labels for each file, but for measuring accuracy for our `test` set classification, which has secret labels, we have to use a more specific function from the `CamUtils` class.\n",
    "\n",
    "The function is called `classification_accuracy()` and it takes $2$ parameters, a list of filenames and the predicted labels associated with those filenames.\n",
    "\n",
    "The result is an accuracy score ratio, between $0.0$ and $1.0$.\n",
    "\n",
    "We can run this function on the `train` set as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_files is the list of files we got way up above\n",
    "CamUtils.classification_accuracy(train_files, train_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink\">\n",
    "What does this mean?<br>\n",
    "Should we expect the same result from the test dataset?<br>\n",
    "Why, or why not?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "Since the training data has labels they can be classified accurately 100% of the time as the model was trained on that data. The test data does not have labels and will be classified based on the model so the accuracy will be less, but will be a more valid measurement of how good our model is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on Test set\n",
    "\n",
    "Now we'll open the image files inside the `./data/image/0801-500/test/` directory, using almost the exact same steps as we did above to create a `DataFrame` with the exception that we don't have labels for these images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: create a list of files in the test/ directory\n",
    "test_files = [f for f in listdir(\"./data/image/0801-500/test\") if f.endswith(\".jpg\")]\n",
    "\n",
    "# TODO: check its length and content\n",
    "display(test_files[0:10])\n",
    "print(len(test_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use a similar loop to extract the pixel information from these images, except we don't have `label` data, just pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pixel_data = []\n",
    "\n",
    "for fname in test_files:\n",
    "  img = PImage.open(path.join(\"./data/image/0801-500/test\", fname))\n",
    "  test_pixel_data.append(get_pixels(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run `PCA` and the `RandomForestClassifier`.\n",
    "\n",
    "Since those are already trained, all we have to do is run their `transform()` function on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: run PCA on test pixels, get DataFrame\n",
    "#       this is the same PCA that was created above, not a new one\n",
    "\n",
    "cam_pca_test_df = pixel_pca.fit_transform(test_pixel_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: take a look at the first 5 rows\n",
    "cam_pca_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's always a good idea to check the result of the `PCA` transformation by looking at the `DataFrame` and reconstructing some images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: reconstruct one or two images\n",
    "\n",
    "pca_pixels_test = pixel_pca.inverse_transform(cam_pca_test_df)\n",
    "\n",
    "# reconstruct image at index 0\n",
    "display(make_image(test_pixel_data[0]))\n",
    "display(make_image(pca_pixels_test.loc[0]))\n",
    "\n",
    "# reconstruct image at index 10\n",
    "display(make_image(test_pixel_data[10]))\n",
    "display(make_image(pca_pixels_test.loc[10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink\"><br>\n",
    "The reconstructed images from the `test` set will always be noisier than the `train` images.<br><br>\n",
    "Why?<br><br>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "Because the model was fit on the training data, not the test data, and we only retained ~0.78 of the original data from the PCA transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Run the classifier and get predicted labels. Then get its accuracy ratio is by running the `CamUtils.classification_accuracy()` function with the list of filenames and list of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# also separate test dataset features\n",
    "test_features = cam_pca_test_df[chosen_columns]\n",
    "\n",
    "# TODO: run classifier. This is the same classifier already fitted on the train data above\n",
    "test_predictions = model_rf.predict(test_features)\n",
    "\n",
    "# TODO: get accuracy\n",
    "CamUtils.classification_accuracy(test_files, test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink\">\n",
    "What's the accuracy ? How could we improve that if we wanted ?<br>\n",
    "How does this compare to the classification model from <code>Homework07</code>? They can both be tuned to perform well, but how many features did we need last time in order to get an accuracy comparable to this?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "The accuracy for the test data is ~0.35, which seems very low and seems like I probably did something wrong. The accuracy from HW07 from just using the first 10 columns was ~0.64, which is significantly higher than using 10 PCA components, and I would expect to have to use fewer PCA columns to get a comparable accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPxe2qYxIG7EblrvD1C4Pmv",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
